---
sidebar: sidebar 
permalink: nvme-rhel-82.html 
keywords: nvme, linux, rhel, red hat, enterprise 
summary: Konfigurieren des NVMe/FC-Hosts für RHEL 8.2 mit ONTAP 
---
= Konfigurieren Sie RHEL 8.2 für NVMe-oF mit ONTAP Speicher
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
Red Hat Enterprise Linux (RHEL)-Hosts unterstützen die Protokolle NVMe over Fibre Channel (NVMe/FC) und NVMe over TCP (NVMe/TCP) mit Asymmetric Namespace Access (ANA).  ANA bietet Multipathing-Funktionalität, die dem asymmetrischen logischen Einheitenzugriff (ALUA) in iSCSI- und FCP-Umgebungen entspricht.

Erfahren Sie, wie Sie NVMe over Fabrics (NVMe-oF)-Hosts für RHEL 8.2 konfigurieren.  Weitere Informationen zu Support und Funktionen finden Sie unterlink:hu-nvme-index.html["NVME-oF-Übersicht"^] .

*NVMe-oF mit RHEL 8.2 weist die folgenden bekannten Einschränkungen auf:*

* SAN-Booten mit dem NVMe-oF-Protokoll wird derzeit nicht unterstützt.
* In-Kernel-NVMe-Multipath ist auf NVMe-oF-Hosts in RHEL 8.2 standardmäßig deaktiviert; Sie müssen es manuell aktivieren.




== Schritt 1: Aktivieren Sie optional den SAN-Bootvorgang

Sie können Ihren Host für die Verwendung von SAN-Boot konfigurieren, um die Bereitstellung zu vereinfachen und die Skalierbarkeit zu verbessern. Verwenden Sie dielink:https://mysupport.netapp.com/matrix/#welcome["Interoperabilitäts-Matrix-Tool"^] um zu überprüfen, ob Ihr Linux-Betriebssystem, Ihr Hostbusadapter (HBA), Ihre HBA-Firmware, Ihr HBA-Boot-BIOS und ONTAP -Version das SAN-Booten unterstützen.

.Schritte
. https://docs.netapp.com/us-en/ontap/san-admin/create-nvme-namespace-subsystem-task.html["Erstellen Sie einen NVMe-Namespace und ordnen Sie ihn dem Host zu"^] .
. Aktivieren Sie das SAN-Booten im Server-BIOS für die Ports, denen der SAN-Boot-Namespace zugeordnet ist.
+
Informationen zum Aktivieren des HBA-BIOS finden Sie in der anbieterspezifischen Dokumentation.

. Starten Sie den Host neu und überprüfen Sie, ob das Betriebssystem läuft.




== Schritt 2: Überprüfen der Softwareversion und der NVMe-Konfiguration

Überprüfen Sie, ob Ihr System die Softwareanforderungen erfüllt, und überprüfen Sie die NVMe-Paketinstallationen und die Hostkonfiguration.

.Schritte
. Installieren Sie RHEL 8.2 auf dem Server.  Überprüfen Sie nach Abschluss der Installation, ob Sie den erforderlichen RHEL 8.2-Kernel ausführen:
+
[source, cli]
----
uname -r
----
+
Beispiel für eine RHEL-Kernelversion:

+
[listing]
----
4.18.0-193.el8.x86_64
----
. Installieren Sie das nvme-cli-Paket:
+
[source, cli]
----
rpm -qa|grep nvme-cli
----
+
Das folgende Beispiel zeigt eine nvme-cli-Paketversion:

+
[listing]
----
nvme-cli-1.9.5.el8.x86_64
----
. Unterstützung für NVMe Multipath im Kernel:
+
[source, cli]
----
grubby –args=nvme_core.multipath=Y –update-kernel /boot/vmlinuz-4.18.0-193.el8.x86_64
----
. Überprüfen Sie auf dem RHEL 8.2-Host die Host-NQN-Zeichenfolge unter `/etc/nvme/hostnqn` :
+
[source, cli]
----
cat /etc/nvme/hostnqn
----
+
Das folgende Beispiel zeigt eine Hostnqn-Zeichenfolge:

+
[listing]
----
nqn.2014-08.org.nvmexpress:uuid:9ed5b327-b9fc-4cf5-97b3-1b5d986345d1
----
. Überprüfen Sie auf dem RHEL 8.2-Host die Zeichenfolge hostnqn unter `/etc/nvme/hostnqn` :
+
[source, cli]
----
vserver nvme subsystem host show -vserver vs_fcnvme_141
----
+
.Beispiel anzeigen
[%collapsible]
====
[listing]
----
Vserver      Subsystem        Host           NQN
----------- --------------- ----------- ---------------
vs_fcnvme_141   nvme_141_1      nqn.2014-08.org.nvmexpress:uuid:9ed5b327-b9fc-4cf5-97b3-1b5d986345d1
----
====
+

NOTE: Wenn die Host-NQN-Zeichenfolgen nicht übereinstimmen, verwenden Sie die `vserver modify` Befehl zum Aktualisieren der Host-NQN-Zeichenfolge auf dem entsprechenden ONTAP Array-Subsystem, damit sie mit der Host-NQN-Zeichenfolge von übereinstimmt `/etc/nvme/hostnqn` auf dem Host.

. Starten Sie den Host neu.
. Aktualisieren Sie optional den `enable_foreign` Einstellung.
+
[NOTE]
====
Um sowohl NVMe- als auch SCSI-Verkehr auf demselben Host auszuführen, empfiehlt NetApp die Verwendung des Kernel-NVMe-Multipath für ONTAP Namespaces und des DM-Multipath für ONTAP -LUNs.  Um zu verhindern, dass dm-multipath ONTAP Namespace-Geräte beansprucht, schließen Sie diese aus, indem Sie den `enable_foreign` Einstellung auf die `/etc/multipath.conf` Datei:

[source, cli]
----
cat /etc/multipath.conf
defaults {
        enable_foreign     NONE
}
----
====
. Starten Sie den Multipathd-Daemon neu, indem Sie ein ausführen `systemctl restart multipathd`.




== Schritt 3: Konfigurieren Sie NVMe/FC für Broadcom/Emulex

Sie können NVMe/FC für Broadcom/Emulex konfigurieren.

.Schritte
. Stellen Sie sicher, dass Sie das unterstützte Adaptermodell verwenden:
+
.. Zeigen Sie die Modellnamen an:
+
[source, cli]
----
cat /sys/class/scsi_host/host*/modelname
----
+
Die folgende Ausgabe sollte angezeigt werden:

+
[listing]
----
LPe32002-M2
LPe32002-M2
----
.. Zeigen Sie die Modellbeschreibungen an:
+
[source, cli]
----
cat /sys/class/scsi_host/host*/modeldesc
----
+
Sie sollten eine Ausgabe ähnlich der folgenden sehen:

+
[listing]
----
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
----


. Stellen Sie sicher, dass die erwartete Ausgabe von `lpfc_enable_fc4_type` auf eingestellt ist `3`:
+
[source, cli]
----
cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
----
. Überprüfen Sie, ob die Initiator-Ports aktiv sind und die Ziel-LIFs sehen können:
+
[source, cli]
----
cat /sys/class/fc_host/host*/port_name
----
+
Sie sollten eine Ausgabe ähnlich der folgenden sehen:

+
[listing]
----
0x100000109b1c1204
0x100000109b1c1205
----
. Überprüfen Sie, ob Ihre Initiator-Ports online sind:
+
[source, cli]
----
cat /sys/class/fc_host/host*/port_state
----
+
Die folgende Ausgabe sollte angezeigt werden:

+
[listing]
----
Online
Online
----
. Vergewissern Sie sich, dass die NVMe/FC-Initiator-Ports aktiviert sind und die Ziel-Ports sichtbar sind:
+
[source, cli]
----
cat /sys/class/scsi_host/host*/nvme_info
----
+
.Beispiel anzeigen
[%collapsible]
====
[listing, subs="+quotes"]
----
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109b1c1204 WWNN x200000109b1c1204 DID x011d00 *ONLINE*
NVME RPORT WWPN x203800a098dfdd91 WWNN x203700a098dfdd91 DID x010c07 *TARGET DISCSRVC ONLINE*
NVME RPORT WWPN x203900a098dfdd91 WWNN x203700a098dfdd91 DID x011507 *TARGET DISCSRVC ONLINE*

NVME Statistics
LS: Xmt 0000000f78 Cmpl 0000000f78 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000002fe29bba Issue 000000002fe29bc4 OutIO 000000000000000a
abort 00001bc7 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00001e15 Err 0000d906

NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109b1c1205 WWNN x200000109b1c1205 DID x011900 *ONLINE*
NVME RPORT WWPN x203d00a098dfdd91 WWNN x203700a098dfdd91 DID x010007 *TARGET DISCSRVC ONLINE*
NVME RPORT WWPN x203a00a098dfdd91 WWNN x203700a098dfdd91 DID x012a07 *TARGET DISCSRVC ONLINE*

NVME Statistics
LS: Xmt 0000000fa8 Cmpl 0000000fa8 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000002e14f170 Issue 000000002e14f17a OutIO 000000000000000a
abort 000016bb noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00001f50 Err 0000d9f8
----
====




== Schritt 4: Optional 1 MB I/O für NVMe/FC aktivieren

ONTAP meldet in den Identify Controller-Daten eine maximale Datenübertragungsgröße (MDTS) von 8.  Dies bedeutet, dass die maximale E/A-Anforderungsgröße bis zu 1 MB betragen kann.  Um E/A-Anfragen der Größe 1 MB für einen Broadcom NVMe/FC-Host auszugeben, sollten Sie die `lpfc` Wert des `lpfc_sg_seg_cnt` Parameter vom Standardwert 64 auf 256.


NOTE: Diese Schritte gelten nicht für Qlogic NVMe/FC-Hosts.

.Schritte
. Setzen Sie den `lpfc_sg_seg_cnt` Parameter auf 256:
+
[source, cli]
----
cat /etc/modprobe.d/lpfc.conf
----
+
Sie sollten eine Ausgabe ähnlich dem folgenden Beispiel sehen:

+
[listing]
----
options lpfc lpfc_sg_seg_cnt=256
----
. Führen Sie den Befehl aus `dracut -f`, und starten Sie den Host neu.
. Stellen Sie sicher, dass der Wert für `lpfc_sg_seg_cnt` 256 lautet:
+
[source, cli]
----
cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
----




== Schritt 5: NVMe-oF validieren

Vergewissern Sie sich, dass der in-Kernel-Multipath-Status, der ANA-Status und die ONTAP-Namespaces für die NVMe-of-Konfiguration richtig sind.

.Schritte
. Vergewissern Sie sich, dass das in-Kernel NVMe Multipath aktiviert ist:
+
[source, cli]
----
cat /sys/module/nvme_core/parameters/multipath
----
+
Die folgende Ausgabe sollte angezeigt werden:

+
[listing]
----
Y
----
. Vergewissern Sie sich, dass die entsprechenden NVMe-of-Einstellungen (z. B. auf NetApp ONTAP-Controller gesetzt auf Modell und Load-Balancing-IOpolicy auf Round-Robin eingestellt) für die jeweiligen ONTAP-Namespaces den Host korrekt widerspiegeln:
+
.. Zeigen Sie die Subsysteme an:
+
[source, cli]
----
cat /sys/class/nvme-subsystem/nvme-subsys*/model
----
+
Die folgende Ausgabe sollte angezeigt werden:

+
[listing]
----
NetApp ONTAP Controller
NetApp ONTAP Controller
----
.. Zeigen Sie die Richtlinie an:
+
[source, cli]
----
cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
----
+
Die folgende Ausgabe sollte angezeigt werden:

+
[listing]
----
round-robin
round-robin
----


. Überprüfen Sie, ob die Namespaces auf dem Host erstellt und richtig erkannt wurden:
+
[source, cli]
----
nvme list
----
+
.Beispiel anzeigen
[%collapsible]
====
[listing]
----
Node         SN                   Model
---------------------------------------------------------
/dev/nvme4n1 81Ix2BVuekWcAAAAAAAB	NetApp ONTAP Controller


Namespace Usage    Format             FW             Rev
-----------------------------------------------------------
1                 21.47 GB / 21.47 GB	4 KiB + 0 B   FFFFFFFF
----
====
. Überprüfen Sie, ob der Controller-Status jedes Pfads aktiv ist und den korrekten ANA-Status aufweist:
+
[source, cli]
----
nvme list-subsys /dev/nvme0n1
----
+
.Beispiel anzeigen
[%collapsible]
====
[listing, subs="+quotes"]
----
Nvme-subsysf0 – NQN=nqn.1992-08.com.netapp:sn.341541339b9511e8a9b500a098c80f09:subsystem.rhel_141_nvme_ss_10_0
\
+- nvme0 fc traddr=nn-0x202c00a098c80f09:pn-0x202d00a098c80f09 host_traddr=nn-0x20000090fae0ec61:pn-0x10000090fae0ec61 *live optimized*
+- nvme1 fc traddr=nn-0x207300a098dfdd91:pn-0x207600a098dfdd91 host_traddr=nn-0x200000109b1c1204:pn-0x100000109b1c1204 *live inaccessible*
+- nvme2 fc traddr=nn-0x207300a098dfdd91:pn-0x207500a098dfdd91 host_traddr=nn-0x200000109b1c1205:pn-0x100000109b1c1205 *live optimized*
+- nvme3 fc traddr=nn-0x207300a098dfdd91:pn-0x207700a098dfdd91 host traddr=nn-0x200000109b1c1205:pn-0x100000109b1c1205 *live inaccessible*
----
====
. Vergewissern Sie sich, dass das NetApp Plug-in für jedes ONTAP Namespace-Gerät die richtigen Werte anzeigt:
+
[role="tabbed-block"]
====
.Spalte
--
[source, cli]
----
nvme netapp ontapdevices -o column
----
.Beispiel anzeigen
[%collapsible]
=====
[listing, subs="+quotes"]
----
Device   Vserver  Namespace Path             NSID   UUID   Size
-------  -------- -------------------------  ------ ----- -----
/dev/nvme0n1   vs_nvme_10       /vol/rhel_141_vol_10_0/rhel_141_ns_10_0    1        55baf453-f629-4a18-9364-b6aee3f50dad   53.69GB
----
=====
--
.JSON
--
[source, cli]
----
nvme netapp ontapdevices -o json
----
.Beispiel anzeigen
[%collapsible]
=====
[listing, subs="+quotes"]
----
{
   "ONTAPdevices" : [
   {
        Device" : "/dev/nvme0n1",
        "Vserver" : "vs_nvme_10",
        "Namespace_Path" : "/vol/rhel_141_vol_10_0/rhel_141_ns_10_0",
         "NSID" : 1,
         "UUID" : "55baf453-f629-4a18-9364-b6aee3f50dad",
         "Size" : "53.69GB",
         "LBA_Data_Size" : 4096,
         "Namespace_Size" : 13107200
    }
]
----
=====
--
====




== Schritt 6: Überprüfen Sie die bekannten Probleme

Es sind keine Probleme bekannt.
