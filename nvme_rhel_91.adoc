---
sidebar: sidebar 
permalink: nvme_rhel_91.html 
keywords: nvme, linux, rhel, red hat, enterprise 
summary: Konfigurieren von NVMe-of Host für RHEL 8.7 mit ONTAP 
---
= NVMe-of-Host-Konfiguration für RHEL 9.1 mit ONTAP
:toc: macro
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toc: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/
:source-highlighter: highlighter.js
:toc-position: content


[role="lead"]
NVMe over Fabrics oder NVMe-of (einschließlich NVMe/FC und NVMe/TCP) werden bei RHEL 9.1 mit Asymmetric Namespace Access (ANA) unterstützt, die für die übrig gebliebene Storage-Failover (SFOs) auf dem ONTAP Array erforderlich sind. ANA ist das ALUA-Äquivalent (Asymmetric Logical Unit Access) in der NVMe-of-Umgebung und wird derzeit mit NVMe Multipath im Kernel implementiert. Dieses Dokument enthält die Details zur Aktivierung von NVMe-of mit in-Kernel NVMe Multipath unter Verwendung von ANA auf RHEL 9.1 und ONTAP als Ziel.

Siehe link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitätsmatrix"^] Finden Sie genaue Details zu unterstützten Konfigurationen.



== Funktionen

* RHEL 9.1 unterstützt zusätzlich zu NVMe/FC NVMe/TCP. Das NetApp Plug-in von original `nvme-cli` Das Paket kann ONTAP-Details sowohl für NVMe/FC als auch für NVMe/TCP-Namespaces anzeigen.
* RHEL 9.1 unterstützt standardmäßig NVMe Multipath in Kernel für NVMe Namespaces, ohne dass explizite Einstellungen erforderlich sind.
* RHEL 9.1 unterstützt die Nutzung von NVMe und SCSI, wobei gleichzeitig auf demselben Host auf einem bestimmten HBA-Adapter ein Verkehr besteht – ohne explizites `dm-multipath` Einstellungen um zu verhindern, dass NVMe-Namespaces beansprucht werden.




== Bekannte Einschränkungen

Das Booten von SAN über das NVMe-of-Protokoll wird derzeit nicht unterstützt.



== NVMe Multipath im Kernel aktivieren

.Schritte
. Installieren Sie RHEL 9.1 auf dem Server. Stellen Sie nach Abschluss der Installation sicher, dass Sie den angegebenen RHEL 9.1-Kernel ausführen. Siehe link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitätsmatrix"^] Erhalten Sie auf der aktuellen Liste der unterstützten Versionen.
. Stellen Sie nach Abschluss der Installation sicher, dass Sie den angegebenen RHEL 9.1-Kernel ausführen. Siehe link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitätsmatrix"^] Erhalten Sie auf der aktuellen Liste der unterstützten Versionen.
+
Beispiel:

+
[listing]
----
# uname -r
 5.14.0-162.6.1.el9_1.x86_64
----
. Installieren Sie den `nvme-cli` Paket:
+
Beispiel:

+
[listing]
----
# rpm -qa|grep nvme-cli
nvme-cli-2.0-4.el9.x86_64
----
. Überprüfen Sie auf dem Host die NQN-Zeichenfolge des Hosts bei `/etc/nvme/hostnqn` Und überprüfen Sie, ob es mit der NQN-Zeichenfolge des Hosts für das entsprechende Subsystem auf dem ONTAP-Array übereinstimmt. Beispiel:
+
[listing]
----

# cat /etc/nvme/hostnqn
nqn.2014-08.org.nvmexpress:uuid:325e7554-1f9b-11ec-8489-3a68dd61a4df


::> vserver nvme subsystem host show -vserver vs_nvme207
Vserver     Subsystem       Host NQN
----------- --------------- ----------------------------------------------------------
vs_nvme207 rhel_207_LPe32002     nqn.2014-08.org.nvmexpress:uuid:325e7554-1f9b-11ec-8489-3a68dd61a4df

----
+

NOTE: Wenn die Host-NQN-Strings nicht übereinstimmen, sollten Sie den verwenden `vserver modify` Befehl zum Aktualisieren der NQN-Zeichenfolge des Hosts auf dem entsprechenden ONTAP-NVMe-Subsystem, um die NQN-Zeichenfolge des Hosts zu entsprechen `/etc/nvme/hostnqn` Auf dem Host.

. Starten Sie den Host neu.




== Konfiguration von NVMe/FC



=== Broadcom/Emulex

.Schritte
. Vergewissern Sie sich, dass Sie den unterstützten Adapter verwenden. Die aktuelle Liste der unterstützten Adapter finden Sie im link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitätsmatrix"^].
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
LPe32002-M2
LPe32002-M2

# cat /sys/class/scsi_host/host*/modeldesc

Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter

----
. Überprüfen Sie, ob Sie die empfohlene Broadcom lpfc-Firmware und den Posteingangstreiber verwenden. Siehe link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitätsmatrix"^] Aktuelle Liste der unterstützten Adaptertreiber- und Firmware-Versionen.
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
14.0.505.11, sli-4:2:c
14.0.505.11, sli-4:2:c
----
+
[listing]
----
# cat /sys/module/lpfc/version
0:14.2.0.5
----
. Verifizieren Sie das `lpfc_enable_fc4_type` Ist auf 3 eingestellt
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3

----
. Überprüfen Sie, ob die Initiator-Ports aktiv sind und ausgeführt werden, und dass Sie die Ziel-LIFs sehen können.
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x100000109b1b95ef
0x100000109b1b95f0
----
+
[listing]
----
# cat /sys/class/fc_host/host*/port_state
Online
Online
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109b1b95ef WWNN x200000109b1b95ef DID x061700 ONLINE
NVME RPORT       WWPN x2035d039ea1308e5 WWNN x2082d039ea1308e5 DID x062f05 TARGET DISCSRVC ONLINE
NVME RPORT       WWPN x2083d039ea1308e5 WWNN x2082d039ea1308e5 DID x062407 TARGET DISCSRVC ONLINE

NVME Statistics
LS: Xmt 000000000e Cmpl 000000000e Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000000001df6c Issue 000000000001df6e OutIO 0000000000000002
        abort 00000000 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000000 Err 00000004

NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109b1b95f0 WWNN x200000109b1b95f0 DID x061400 ONLINE
NVME RPORT       WWPN x2036d039ea1308e5 WWNN x2082d039ea1308e5 DID x061605 TARGET DISCSRVC ONLINE
NVME RPORT       WWPN x2037d039ea1308e5 WWNN x2082d039ea1308e5 DID x062007 TARGET DISCSRVC ONLINE

NVME Statistics
LS: Xmt 000000000e Cmpl 000000000e Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000000001dd28 Issue 000000000001dd29 OutIO 0000000000000001
        abort 00000000 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000000 Err 00000004

----




==== 1 MB I/O-Größe aktivieren (optional)

ONTAP meldet in den Identify Controller-Daten ein MDTS (MAX Data Transfer Size) von 8, was bedeutet, dass die maximale E/A-Anforderungsgröße bis zu 1 MB betragen sollte. Um jedoch E/A-Anforderungen von 1 MB für den Broadcom NVMe/FC-Host zu geben, sollte der lpfc-Parameter lpfc_sg_seg_cnt auch bis zu 256 vom Standardwert 64 angestoßen werden. Befolgen Sie dazu die folgenden Anweisungen:

.Schritte
. Fügen Sie den Wert hinzu `256` In den jeweiligen Bereichen ein `modprobe lpfc.conf` Datei:
+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_sg_seg_cnt=256
----
. A ausführen `dracut -f` Führen Sie einen Befehl aus, und starten Sie den Host neu.
. Überprüfen Sie nach dem Neustart, ob die oben genannte Einstellung angewendet wurde, indem Sie die entsprechende Option prüfen `sysfs` Wert:
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
256
----
+
Jetzt sollte der Broadcom FC-NVMe-Host bis zu 1 MB I/O-Anfragen an den ONTAP Namespace-Geräten senden können.





=== Marvell/QLogic

Im nativen Posteingang `qla2xxx` Der im RHEL 9.1 Kernel enthaltene Treiber verfügt über die neuesten Upstream-Fixes, die für die ONTAP-Unterstützung von entscheidender Bedeutung sind.

.Schritte
. Überprüfen Sie, ob Sie den unterstützten Adaptertreiber und die unterstützte Firmware-Version mit dem folgenden Befehl ausführen:
+
[listing]
----
# cat /sys/class/fc_host/host*/symbolic_name
QLE2772 FW:v9.08.02 DVR:v10.02.07.400-k-debug
QLE2772 FW:v9.08.02 DVR:v10.02.07.400-k-debug
----
. Verifizieren `ql2xnvmeenable` Ist gesetzt, sodass der Marvell-Adapter unter Verwendung des folgenden Befehls als NVMe/FC-Initiator fungieren kann:
+
[listing]
----
# cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
1
----




== Konfiguration von NVMe/TCP

Im Gegensatz zu NVMe/FC verfügt NVMe/TCP über keine automatische Verbindungsfunktion. Es gibt zwei wesentliche Einschränkungen für den Linux NVMe/TCP-Host:

* *Kein automatischer erneuten Verbindungsaufbau nach der Wiederherstellung von Pfaden* NVMe/TCP kann nicht automatisch eine Verbindung zu einem Pfad herstellen, der über den Standard hinaus wiederhergestellt ist `ctrl-loss-tmo` Timer von 10 Minuten nach einem Pfad nach unten.
* *Während des Hoststarts ist keine automatische Verbindung möglich* NVMe/TCP kann beim Hoststart keine automatische Verbindung herstellen.


Sie sollten den Wiederholungszeitraum für Failover-Ereignisse auf mindestens 30 Minuten einstellen, um Zeitüberschreitungen zu vermeiden. Sie können den Wiederholungszeitraum erhöhen, indem Sie den Wert des erhöhen `ctrl_loss_tmo timer` Gehen Sie wie folgt vor:

.Schritte
. Überprüfen Sie, ob der Initiator-Port die Daten der Erkennungsprotokollseiten in den unterstützten NVMe/TCP LIFs abrufen kann:
+
[listing]
----
# nvme discover -t tcp -w 192.168.1.8 -a 192.168.1.51

Discovery Log Number of Records 10, Generation counter 119
=====Discovery Log Entry 0======
trtype: tcp
adrfam: ipv4
subtype: nvme subsystem
treq: not specified
portid: 0
trsvcid: 4420
subnqn: nqn.1992-08.com.netapp:sn.56e362e9bb4f11ebbaded039ea165abc:subsystem.nvme_118_tcp_1
traddr: 192.168.2.56
sectype: none
=====Discovery Log Entry 1======
trtype: tcp
adrfam: ipv4
subtype: nvme subsystem
treq: not specified
portid: 1
trsvcid: 4420
subnqn: nqn.1992-08.com.netapp:sn.56e362e9bb4f11ebbaded039ea165abc:subsystem.nvme_118_tcp_1
traddr: 192.168.1.51
sectype: none
=====Discovery Log Entry 2======
trtype: tcp
adrfam: ipv4
subtype: nvme subsystem
treq: not specified
portid: 0
trsvcid: 4420
subnqn: nqn.1992-08.com.netapp:sn.56e362e9bb4f11ebbaded039ea165abc:subsystem.nvme_118_tcp_2
traddr: 192.168.2.56
sectype: none
...
----
. Überprüfen Sie, ob die anderen LIF-Kombos des NVMe/TCP-Initiators erfolgreich die Daten der Erkennungsprotokoll-Seite abrufen können. Beispiel:
+
[listing]
----
# nvme discover -t tcp -w 192.168.1.8 -a 192.168.1.51
# nvme discover -t tcp -w 192.168.1.8 -a 192.168.1.52
# nvme discover -t tcp -w 192.168.2.9 -a 192.168.2.56
# nvme discover -t tcp -w 192.168.2.9 -a 192.168.2.57
----
. Laufen `nvme connect-all` Befehl über alle unterstützten NVMe/TCP-Initiator-Ziel-LIFs über die Nodes hinweg Stellen Sie sicher, dass Sie einen längeren Zeitraum festlegen `ctrl_loss_tmo` Zeitschaltuhr-Wiederholungszeitraum (z. B. 30 Minuten, die über eingestellt werden kann `-l 1800`) Während der Ausführung des `connect-all` Befehl, damit es im Falle eines Pfadausfalls für einen längeren Zeitraum versuchen würde. Beispiel:
+
[listing]
----
# nvme connect-all -t tcp -w 192.168.1.8 -a 192.168.1.51 -l 1800
# nvme connect-all -t tcp -w 192.168.1.8 -a 192.168.1.52 -l 1800
# nvme connect-all -t tcp -w 192.168.2.9 -a 192.168.2.56 -l 1800
# nvme connect-all -t tcp -w 192.168.2.9 -a 192.168.2.57 -l 1800
----




== NVMe-of validieren

.Schritte
. Überprüfung des NVMe Multipath im Kernel durch Prüfung:
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y
----
. Vergewissern Sie sich, dass die entsprechenden NVMe-of Einstellungen (z. B. `model` Auf einstellen `NetApp ONTAP Controller` Und Lastverteilung `iopolicy` Auf einstellen `round-robin`) Für die jeweiligen ONTAP-Namespaces richtig reflektieren auf dem Host:
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller
----
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. Vergewissern Sie sich, dass die ONTAP-Namespaces auf dem Host ordnungsgemäß reflektieren. Beispiel:
+
[listing]
----
# nvme list
Node           SN                    Model                   Namespace
------------   --------------------- ---------------------------------
/dev/nvme0n1   81CZ5BQuUNfGAAAAAAAB   NetApp ONTAP Controller   1

Usage                Format         FW Rev
-------------------  -----------    --------
85.90 GB / 85.90 GB  4 KiB + 0 B    FFFFFFFF
----
. Überprüfen Sie, ob der Controller-Status jedes Pfads aktiv ist und den korrekten ANA-Status aufweist. Beispiel:
+
Beispiel (A):

+
[listing, subs="+quotes"]
----
# nvme list-subsys /dev/nvme0n1
nvme-subsys10 - NQN=nqn.1992-08.com.netapp:sn.82e7f9edc72311ec8187d039ea14107d:subsystem.rhel_131_QLe2742
\
 +- nvme2 fc traddr=nn-0x2038d039ea1308e5:pn-0x2039d039ea1308e5,host_traddr=nn-0x20000024ff171d30:pn-0x21000024ff171d30 live non-optimized
 +- nvme3 fc traddr=nn-0x2038d039ea1308e5:pn-0x203cd039ea1308e5,host_traddr=nn-0x20000024ff171d31:pn-0x21000024ff171d31 live optimized
 +- nvme4 fc traddr=nn-0x2038d039ea1308e5:pn-0x203bd039ea1308e5,host_traddr=nn-0x20000024ff171d30:pn-0x21000024ff171d30 live optimized
 +- nvme5 fc traddr=nn-0x2038d039ea1308e5:pn-0x203ad039ea1308e5,host_traddr=nn-0x20000024ff171d31:pn-0x21000024ff171d31 live non-optimized

----
+
Beispiel (b):

+
[listing]
----
# nvme list-subsys /dev/nvme0n1
nvme-subsys1 - NQN=nqn.1992-08.com.netapp:sn.bf0691a7c74411ec8187d039ea14107d:subsystem.rhel_tcp_133
\
 +- nvme1 tcp traddr=192.168.166.21,trsvcid=4420,host_traddr=192.168.166.5 live non-optimized
 +- nvme2 tcp traddr=192.168.166.20,trsvcid=4420,host_traddr=192.168.166.5 live optimized
 +- nvme3 tcp traddr=192.168.167.21,trsvcid=4420,host_traddr=192.168.167.5 live non-optimized
 +- nvme4 tcp traddr=192.168.167.20,trsvcid=4420,host_traddr=192.168.167.5 live optimized
----
. Überprüfen Sie, ob das NetApp Plug-in die richtigen Werte für jedes ONTAP Namespace-Gerät anzeigt. Beispiel:
+
[listing]
----
# nvme netapp ontapdevices -o column
Device       Vserver          Namespace Path
---------    -------          --------------------------------------------------
/dev/nvme0n1 vs_tcp79     /vol/vol1/ns1 

NSID  UUID                                   Size
----  ------------------------------         ------
1     79c2c569-b7fa-42d5-b870-d9d6d7e5fa84  21.47GB


# nvme netapp ontapdevices -o json
{

  "ONTAPdevices" : [
  {

      "Device" : "/dev/nvme0n1",
      "Vserver" : "vs_tcp79",
      "Namespace_Path" : "/vol/vol1/ns1",
      "NSID" : 1,
      "UUID" : "79c2c569-b7fa-42d5-b870-d9d6d7e5fa84",
      "Size" : "21.47GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 5242880
    },

]

}
----
+
Beispiel (b)

+
[listing]
----
# nvme netapp ontapdevices -o column

Device           Vserver                   Namespace Path
---------------- ------------------------- -----------------------------------
/dev/nvme1n1     vs_tcp_133                /vol/vol1/ns1

NSID UUID                                   Size
-------------------------------------------------------
1    1ef7cb56-bfed-43c1-97c1-ef22eeb92657   21.47GB

# nvme netapp ontapdevices -o json
{
  "ONTAPdevices":[
    {
      "Device":"/dev/nvme1n1",
      "Vserver":"vs_tcp_133",
      "Namespace_Path":"/vol/vol1/ns1",
      "NSID":1,
      "UUID":"1ef7cb56-bfed-43c1-97c1-ef22eeb92657",
      "Size":"21.47GB",
      "LBA_Data_Size":4096,
      "Namespace_Size":5242880
    },
  ]

}
----




== Bekannte Probleme

Die NVMe-of-Hostkonfiguration für RHEL 9.1 mit ONTAP weist folgende bekannte Probleme auf:

[cols="10,30,30,10"]
|===
| NetApp Bug ID | Titel | Beschreibung | Bugzilla-ID 


| 1503468 | `nvme list-subsys` Der Befehl gibt die sich wiederholende nvme-Controller-Liste für ein bestimmtes Subsystem zurück | Der `nvme list-subsys` Befehl sollte eine eindeutige Liste der nvme Controller zurückgeben, die einem bestimmten Subsystem zugeordnet sind. In RHEL 9.1 zeigt die `nvme list-subsys` Befehl gibt nvme Controller für alle Namespaces zurück, die zu einem bestimmten Subsystem gehören. Der ANA-Status ist jedoch ein per-Namespace-Attribut. Daher wäre es ideal, eindeutige nvme-Controller-Einträge mit dem Pfadstatus anzuzeigen, wenn Sie die Subsystem-Befehlssyntax für einen bestimmten Namespace auflisten. | 2130106 
|===