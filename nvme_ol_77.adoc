---
sidebar: sidebar 
permalink: nvme_ol_77.html 
keywords: nvme, linux, oracle, 7.7 
summary: Beschreibt die Konfiguration von NVMe/FC für Oracle Linux 7.7 mit ONTAP 
---
= NVMe/FC-Host-Konfiguration für Oracle Linux 7.7 mit ONTAP
:toc: macro
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toc: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/
:toc-position: content




== Instandhaltung

NVMe/FC wird auf ONTAP 9.6 oder höher für die folgenden Versionen von Oracle Linux unterstützt

* OL 7.7
+
OL 7.7 Host kann NVMe- und SCSI-Datenverkehr über dieselben Fibre Channel-Initiator-Adapter-Ports ausführen. Siehe link:https://hwu.netapp.com/Home/Index["Hardware Universe"^] Für eine Liste der unterstützten FC-Adapter und Controller.

+
Die aktuelle Liste der unterstützten Konfigurationen finden Sie im link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitätsmatrix"^].




NOTE: Sie können die in diesem Dokument angegebenen Konfigurationseinstellungen verwenden, um die mit verbundenen Cloud-Clients zu konfigurieren link:https://docs.netapp.com/us-en/cloud-manager-cloud-volumes-ontap/index.html["Cloud Volumes ONTAP"^] Und link:https://docs.netapp.com/us-en/cloud-manager-fsx-ontap/index.html["Amazon FSX für ONTAP"^].



== Bekannte Einschränkungen

* Native NVMe/FC-Skripte für automatische Verbindungen sind im nvme-cli-Paket nicht verfügbar. Sie können die vom HBA-Anbieter bereitgestellten externen Skripts zur automatischen Verbindung verwenden.
* Standardmäßig ist der Round-Robin-Lastenausgleich nicht aktiviert. Sie müssen eine udev-Regel schreiben, um diese Funktion zu aktivieren. Im Abschnitt über die Aktivierung von NVMe/FC auf OL 7.7 werden Schritte ausgeführt.
* Das Booten von SAN über das NVMe-of-Protokoll wird derzeit nicht unterstützt.




== Aktivieren von NVMe auf OL 7.7

. Stellen Sie sicher, dass der standardmäßige Oracle Linux 7.7-Kernel installiert ist.
. Starten Sie den Host neu, und überprüfen Sie, ob er in den angegebenen OL 7.7-Kernel startet.
+
[listing]
----
# uname -r
4.14.35-1902.9.2.el7uek
----
. Upgrade auf das paket nvme-cli-1.8.1-3.el7.
+
[listing]
----
# rpm -qa|grep nvme-cli
nvme-cli-1.8.1-3.el7.x86_64
----
. Fügen Sie die folgende Zeichenfolge als separate udev-Regel bei hinzu `/lib/udev/rules.d/71-nvme-iopolicy-netapp-ONTAP.rules`. Dies ermöglicht Lastverteilung per Round Robin für NVMe Multipath.
+
[listing]
----
# Enable round-robin for NetApp ONTAP
ACTION==”add”, SUBSYSTEM==”nvme-subsystem”, ATTR{model}==”NetApp ONTAP Controller”, ATTR{iopolicy}=”round-robin
----
. Prüfen Sie auf dem OL 7.7-Host die Host-NQN-Zeichenfolge unter `/etc/nvme/hostnqn` Und überprüfen Sie, ob es mit der NQN-Zeichenfolge des Hosts für das entsprechende Subsystem auf dem ONTAP-Array übereinstimmt.
+
[listing]
----
# cat /etc/nvme/hostnqn
nqn.2014-08.org.nvmexpress:uuid:75953f3b-77fe-4e03-bf3c-09d5a156fbcd
----
+
[listing]
----
*> vserver nvme subsystem host show -vserver vs_nvme_10
Vserver Subsystem Host NQN
------- --------- -------------------------------------- -----------
ol_157_nvme_ss_10_0
nqn.2014-08.org.nvmexpress:uuid:75953f3b-77fe-4e03-bf3c-09d5a156fbcd
----



NOTE: Wenn die Host-NQN-Strings nicht übereinstimmen, sollten Sie den vserver modify-Befehl verwenden, um die NQN-Zeichenfolge des Hosts auf dem entsprechenden ONTAP-Array-Subsystem zu aktualisieren, damit sie mit der NQN-Zeichenfolge des Hosts von übereinstimmt `/etc/nvme/hostnqn` Auf dem Host.

. Starten Sie den Host neu.




== Konfigurieren des Broadcom FC-Adapters für NVMe/FC

. Vergewissern Sie sich, dass Sie den unterstützten Adapter verwenden. Die aktuelle Liste der unterstützten Adapter finden Sie im link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitätsmatrix"^].
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
LPe32002-M2
LPe32002-M2
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/modeldesc
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
----
. Kopieren Sie das Broadcom outbox Auto-Connect-Skripte-Paket und installieren Sie es.
+
[listing]
----
# rpm -ivh nvmefc-connect-12.4.65.0-1.noarch.rpm
----
. Starten Sie den Host neu.
. Stellen Sie sicher, dass Sie die empfohlene Broadcom lpfc-Firmware, den nativen Inbox-Treiber und die Paketversionen für automatische Verbindungen verwenden. Eine Liste der unterstützten Versionen finden Sie im link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitätsmatrix"^].
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
12.4.243.17, sil-4.2.c
12.4.243.17, sil-4.2.c

# cat /sys/module/lpfc/version
0:12.0.0.10

# rpm -qa | grep nvmefc
nvmefc-connect-12.4.65.0-1.noarch
----
. Stellen Sie sicher, dass lpfc_enable_fc4_type auf 3 gesetzt ist.
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. Vergewissern Sie sich, dass die Initiator-Ports ausgeführt werden.
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x10000090fae0ec61
0x10000090fae0ec62
----
+
[listing]
----
# cat /sys/class/fc_host/host*/port_state
Online
Online
----
. Vergewissern Sie sich, dass die NVMe/FC-Initiator-Ports aktiviert sind und die Ziel-LIFs ausgeführt werden können.
+
[listing]
----
# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 NVME 2947 SCSI 2977 ELS 250
NVME LPORT lpfc0 WWPN x10000090fae0ec61 WWNN x20000090fae0ec61 DID x012000 ONLINE
NVME RPORT WWPN x202d00a098c80f09 WWNN x202c00a098c80f09 DID x010201 TARGET DISCSRVC ONLINE
NVME RPORT WWPN x203100a098c80f09 WWNN x202c00a098c80f09 DID x010601 TARGET DISCSRVC ONLINE
NVME Statistics
…
----




== Validierung von NVMe/FC

. Überprüfen Sie die folgenden NVMe/FC-Einstellungen.
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y

# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller

# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. Vergewissern Sie sich, dass die Namespaces erstellt wurden.
+
[listing]
----
# nvme list
Node SN Model Namespace Usage Format FW Rev
---------------- -------------------- -----------------------
/dev/nvme0n1 80BADBKnB/JvAAAAAAAC NetApp ONTAP Controller 1 53.69 GB / 53.69 GB 4 KiB + 0 B FFFFFFFF
----
. Überprüfen Sie den Status der ANA-Pfade.
+
[listing]
----
# nvme list-subsys/dev/nvme0n1
Nvme-subsysf0 – NQN=nqn.1992-08.com.netapp:sn.341541339b9511e8a9b500a098c80f09:subsystem.ol_157_nvme_ss_10_0
\
+- nvme0 fc traddr=nn-0x202c00a098c80f09:pn-0x202d00a098c80f09 host_traddr=nn-0x20000090fae0ec61:pn-0x10000090fae0ec61 live optimized
+- nvme1 fc traddr=nn-0x207300a098dfdd91:pn-0x207600a098dfdd91 host_traddr=nn-0x200000109b1c1204:pn-0x100000109b1c1204 live inaccessible
+- nvme2 fc traddr=nn-0x207300a098dfdd91:pn-0x207500a098dfdd91 host_traddr=nn-0x200000109b1c1205:pn-0x100000109b1c1205 live optimized
+- nvme3 fc traddr=nn-0x207300a098dfdd91:pn-0x207700a098dfdd91 host traddr=nn-0x200000109b1c1205:pn-0x100000109b1c1205 live inaccessible
----
. Überprüfen Sie das NetApp Plug-in für ONTAP Geräte.
+
[listing]
----
# nvme netapp ontapdevices -o column
Device   Vserver  Namespace Path             NSID   UUID   Size
-------  -------- -------------------------  ------ ----- -----
/dev/nvme0n1   vs_nvme_10       /vol/rhel_141_vol_10_0/ol_157_ns_10_0    1        55baf453-f629-4a18-9364-b6aee3f50dad   53.69GB

# nvme netapp ontapdevices -o json
{
   "ONTAPdevices" : [
   {
        Device" : "/dev/nvme0n1",
        "Vserver" : "vs_nvme_10",
        "Namespace_Path" : "/vol/rhel_141_vol_10_0/ol_157_ns_10_0",
         "NSID" : 1,
         "UUID" : "55baf453-f629-4a18-9364-b6aee3f50dad",
         "Size" : "53.69GB",
         "LBA_Data_Size" : 4096,
         "Namespace_Size" : 13107200
    }
]
----




== Aktivieren der 1-MB-I/O-Größe für Broadcom NVMe/FC

ONTAP meldet eine MDTS (MAX Data-Übertragungsgröße) von 8 in den Identifizieren-Controller-Daten, was bedeutet, dass die maximale E/A-Anforderungsgröße bis zu 1 MB betragen kann. Um jedoch I/O-Anforderungen von Größe 1 MB für einen Broadcom-NVMe/FC-Host auszustellen, müssen Sie den erhöhen `lpfc` Wert des `lpfc_sg_seg_cnt` Parameter auf 256 ab dem Standardwert 64.

.Schritte
. Stellen Sie die ein `lpfc_sg_seg_cnt` Parameter bis 256.
+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_sg_seg_cnt=256
----
. A ausführen `dracut -f` Führen Sie einen Befehl aus, und starten Sie den Host neu.
. Verifizieren Sie das `lpfc_sg_seg_cnt` Ist 256.
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
256
----



NOTE: Dies gilt nicht für Qlogic NVMe/FC-Hosts.



== LPFC ausführliche Protokollierung

Legen Sie den lpfc-Treiber für NVMe/FC fest.

.Schritte
. Stellen Sie die ein `lpfc_log_verbose` Treibereinstellung auf einen der folgenden Werte, um NVMe/FC-Ereignisse zu protokollieren.
+
[listing]
----
#define LOG_NVME 0x00100000 /* NVME general events. */
#define LOG_NVME_DISC 0x00200000 /* NVME Discovery/Connect events. */
#define LOG_NVME_ABTS 0x00400000 /* NVME ABTS events. */
#define LOG_NVME_IOERR 0x00800000 /* NVME IO Error events. */
----
. Führen Sie nach dem Festlegen der Werte den aus `dracut-f` Führen Sie einen Befehl aus und starten Sie den Host neu.
. Überprüfen Sie die Einstellungen.
+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_log_verbose=0xf00083

# cat /sys/module/lpfc/parameters/lpfc_log_verbose
15728771
----

