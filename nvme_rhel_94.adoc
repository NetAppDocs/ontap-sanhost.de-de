---
sidebar: sidebar 
permalink: nvme_rhel_94.html 
keywords: nvme, linux, rhel, red hat, enterprise 
summary: Konfigurieren des NVMe-of-Hosts für RHEL 9.4 mit ONTAP 
---
= NVMe-of Hostkonfiguration für RHEL 9.4 mit ONTAP
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
NVMe over Fabrics (NVMe-of), einschließlich NVMe over Fibre Channel (NVMe/FC) und andere Übertragungen werden mit Red hat Enterprise Linux (RHEL) 9.4 mit Asymmetric Namespace Access (ANA) unterstützt. In NVMe-of Umgebungen entspricht ANA ALUA Multipathing in iSCSI- und FC-Umgebungen und wird mit in-Kernel NVMe Multipath implementiert.

Folgende Unterstützung ist für die NVMe-of-Hostkonfiguration für RHEL 9.4 mit ONTAP verfügbar:

* Unterstützung für NVMe over TCP (NVMe/TCP) neben NVMe/FC Das NetApp-Plug-in im nativen `nvme-cli` Package zeigt ONTAP-Details sowohl für NVMe/FC- als auch für NVMe/TCP-Namespaces an.
* Verwendung von gleichzeitig vorhandenem NVMe und SCSI Traffic auf demselben Host in einem bestimmten Host Bus Adapter (HBA) ohne die expliziten dm-Multipath-Einstellungen, um die Inanspruchnahme von NVMe-Namespaces zu verhindern.


Weitere Informationen zu unterstützten Konfigurationen finden Sie im link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitäts-Matrix-Tool"^].



== Funktionen

* RHEL 9.4 hat standardmäßig in-Kernel-NVMe-Multipath für NVMe-Namespaces aktiviert; daher sind keine expliziten Einstellungen erforderlich.
* SAN-Booting über das NVMe/FC-Protokoll wird unterstützt.




== Bekannte Einschränkungen

Es gibt keine bekannten Einschränkungen.



== Validieren der Softwareversionen

Mit dem folgenden Verfahren können Sie die unterstützten Mindestversionen von RHEL 9.4 validieren.

.Schritte
. Installieren Sie RHEL 9.4 auf dem Server. Überprüfen Sie nach Abschluss der Installation, ob Sie den angegebenen RHEL 9.4-Kernel ausführen:
+
[listing]
----
# uname -r
----
+
*Beispielausgabe:*

+
[listing]
----
5.14.0-423.el9.x86_64
----
. Installieren Sie den `nvme-cli` Paket:
+
[listing]
----
# rpm -qa|grep nvme-cli
----
+
*Beispielausgabe:*

+
[listing]
----
nvme-cli-2.6-4.el9.x86_64
----
. Installieren Sie den `libnvme` Paket:
+
[listing]
----
#rpm -qa|grep libnvme
----
+
*Beispielausgabe*

+
[listing]
----
libnvme-1.6-1.el9.x86_64
----
. Überprüfen Sie auf dem RHEL 9.4-Host die hostnqn-Zeichenfolge unter `/etc/nvme/hostnqn`:
+
[listing]
----
# cat /etc/nvme/hostnqn
----
+
*Beispielausgabe*

+
[listing]
----
nqn.2014-08.org.nvmexpress:uuid: uuid:4c4c4544-0036-5610-804a-c7c04f365a32
----
. Überprüfen Sie das `hostnqn` Die Zeichenfolge entspricht der `hostnqn` String für das entsprechende Subsystem auf dem ONTAP-Array:
+
[listing]
----
::> vserver nvme subsystem host show -vserver vs_coexistence_LPE36002
----
+
*Beispielausgabe:*

+
[listing]
----
Vserver     Subsystem          Host NQN
----------- --------------- ----------------------------------------------------------
vs_coexistence_LPE36002   nvme    nqn.2014-08.org.nvmexpress:uuid: 4c4c4544-0036-5610-804a-
----
+

NOTE: Wenn der `hostnqn` Zeichenfolgen stimmen nicht überein. Verwenden Sie die `vserver modify` Befehl zum Aktualisieren des `hostnqn` Zeichenfolge auf dem entsprechenden ONTAP-Array-Subsystem, die dem entspricht `hostnqn` Zeichenfolge von `/etc/nvme/hostnqn` Auf dem Host.





== Konfiguration von NVMe/FC

Sie können NVMe/FC für Broadcom/Emulex- oder Marvell/Qlogic-Adapter konfigurieren.

[role="tabbed-block"]
====
.Broadcom/Emulex
--
.Schritte
. Stellen Sie sicher, dass Sie das unterstützte Adaptermodell verwenden:
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
----
+
*Beispielausgabe:*

+
[listing]
----
LPe36002-M64
LPe36002-M64

----
+
[listing]
----
# cat /sys/class/scsi_host/host*/modeldesc
----
+
*Beispielausgabe:*

+
[listing]
----
Emulex LightPulse LPe36002-M64 2-Port 64Gb Fibre Channel Adapter
Emulex LightPulse LPe36002-M64 2-Port 64Gb Fibre Channel Adapter
----
. Vergewissern Sie sich, dass Sie das empfohlene Broadcom verwenden `lpfc` Firmware und Inbox-Treiber:
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
14.2.673.40, sli-4:6:d
14.2.673.40, sli-4:6:d


# cat /sys/module/lpfc/version
0:14.2.0.16
----
+
Die aktuelle Liste der unterstützten Adaptertreiber- und Firmware-Versionen finden Sie unter link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitäts-Matrix-Tool"^].

. Verifizieren Sie das `lpfc_enable_fc4_type` Ist auf festgelegt `3`:
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. Vergewissern Sie sich, dass die Initiator-Ports ausgeführt werden und dass die Ziel-LIFs angezeigt werden:
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x100000109b3c081f
0x100000109b3c0820

----
+
[listing]
----
# cat /sys/class/fc_host/host*/port_state
Online
Online
----
+
[listing, subs="+quotes"]
----
# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109b3c081f WWNN x200000109b3c081f DID x062300 *ONLINE*
NVME RPORT       WWPN x2143d039ea165877 WWNN x2142d039ea165877 DID x061b15 *TARGET DISCSRVC ONLINE*
NVME RPORT       WWPN x2145d039ea165877 WWNN x2142d039ea165877 DID x061115 *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 000000040b Cmpl 000000040b Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000001f5c4538 Issue 000000001f58da22 OutIO fffffffffffc94ea
abort 00000630 noxri 00000000 nondlp 00001071 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000630 Err 0001bd4a
NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109b3c0820 WWNN x200000109b3c0820 DID x062c00 *ONLINE*
NVME RPORT       WWPN x2144d039ea165877 WWNN x2142d039ea165877 DID x060215 *TARGET DISCSRVC ONLINE*
NVME RPORT       WWPN x2146d039ea165877 WWNN x2142d039ea165877 DID x061815 *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 000000040b Cmpl 000000040b Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000001f5c3618 Issue 000000001f5967a4 OutIO fffffffffffd318c
abort 00000629 noxri 00000000 nondlp 0000044e qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000629 Err 0001bd3d

----


--
.Marvell/QLogic FC Adapter für NVMe/FC
--
Der native Inbox qla2xxx Treiber, der im RHEL 9.4 GA Kernel enthalten ist, hat die neuesten Fehlerbehebungen. Diese Fehlerbehebungen sind für die Unterstützung von ONTAP unerlässlich.

.Schritte
. Vergewissern Sie sich, dass der unterstützte Adaptertreiber und die unterstützten Firmware-Versionen ausgeführt werden:
+
[listing]
----
# cat /sys/class/fc_host/host*/symbolic_name
----
+
*Beispielausgabe*

+
[listing]
----
QLE2872 FW:v9.12.01 DVR:v10.02.09.100-k
QLE2872 FW:v9.12.01 DVR:v10.02.09.100-k
----
. Verifizieren Sie das `ql2xnvmeenable` Ist festgelegt. Dadurch kann der Marvell Adapter als NVMe/FC-Initiator verwendet werden:
+
[listing]
----
# cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
1
----


--
====


=== 1 MB E/A aktivieren (optional)

ONTAP meldet eine MDTS (MAX Data-Übertragungsgröße) von 8 in den Identifizieren von Controller-Daten. Das bedeutet, dass die maximale E/A-Anforderungsgröße bis zu 1 MB betragen kann. Um I/O-Anforderungen von Größe 1 MB für einen Broadcom-NVMe/FC-Host auszustellen, müssen Sie den `lpfc` Wert des `lpfc_sg_seg_cnt` Parameters ab dem Standardwert 64 auf 256 erhöhen.


NOTE: Die folgenden Schritte gelten nicht für Qlogic NVMe/FC-Hosts.

.Schritte
. Setzen Sie den `lpfc_sg_seg_cnt` Parameter auf 256:
+
[listing]
----
cat /etc/modprobe.d/lpfc.conf
----
+
.Beispielausgabe
[listing]
----
options lpfc lpfc_sg_seg_cnt=256
----
. Führen Sie den Befehl aus `dracut -f`, und starten Sie den Host neu:
. Stellen Sie sicher, dass `lpfc_sg_seg_cnt` 256:
+
[listing]
----
cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
----
+
Der erwartete Wert ist 256.





== Konfiguration von NVMe/TCP

NVMe/TCP verfügt nicht über eine automatische Verbindungsfunktion. Stattdessen können Sie die NVMe/TCP-Subsysteme und -Namespaces erkennen, indem Sie NVMe/TCP oder `connect-all` Vorgänge manuell ausführen `connect`.

.Schritte
. Vergewissern Sie sich, dass der Initiator-Port die Daten der Erkennungsprotokollseite über die unterstützten NVMe/TCP-LIFs abrufen kann:
+
[listing]
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
*Beispielausgabe:*

+
[listing, subs="+quotes"]
----
# nvme discover -t tcp -w 192.168.167.1 -a 192.168.167.16

Discovery Log Number of Records 8, Generation counter 10
=====Discovery Log Entry 0======
trtype:  tcp
adrfam:  ipv4
subtype: current discovery subsystem
treq:    not specified
portid:  11
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:
discovery
traddr:  192.168.167.8
eflags:  explicit discovery connections, duplicate discovery information
sectype: none
=====Discovery Log Entry 1======
trtype:  tcp
adrfam:  ipv4
subtype: current discovery subsystem
treq:    not specified
portid:  9
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:
discovery
traddr:  192.168.166.8
eflags:  explicit discovery connections, duplicate discovery information
sectype: none
=====Discovery Log Entry 2======
trtype:  tcp
adrfam:  ipv4
subtype: current discovery subsystem
treq:    not specified
portid:  12
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:
discovery
traddr:  192.168.167.7
eflags:  explicit discovery connections, duplicate discovery information
sectype: none
=====Discovery Log Entry 3======
trtype:  tcp
adrfam:  ipv4
subtype: current discovery subsystem
treq:    not specified
portid:  10
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:
discovery
traddr:  192.168.166.7
eflags:  explicit discovery connections, duplicate discovery information
sectype: none
=====Discovery Log Entry 4======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  11
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:subsystem.nvme_tcp_1
traddr:  192.168.167.8
eflags:  none
sectype: none
=====Discovery Log Entry 5======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  9
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:subsystem.nvme_tcp_1
traddr:  192.168.166.8
eflags:  none
sectype: none
=====Discovery Log Entry 6======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  12
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:subsystem.nvme_tcp_1
traddr:  192.168.167.7
eflags:  none
sectype: none
=====Discovery Log Entry 7======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  10
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:subsystem.nvme_tcp_1
traddr:  192.168.166.7
eflags:  none
sectype: none
----
. Vergewissern Sie sich, dass die anderen LIF-Kombinationen des NVMe/TCP-Initiators erfolgreich beim Abrufen von Protokollseitendaten der Bestandsaufnahme abgerufen werden können:
+
[listing]
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
*Beispielausgabe:*

+
[listing]
----
#nvme discover -t tcp -w 192.168.166.6 -a 192.168.166.7
#nvme discover -t tcp -w 192.168.166.6 -a 192.168.166.8
#nvme discover -t tcp -w 192.168.167.6 -a 192.168.167.7
#nvme discover -t tcp -w 192.168.167.6 -a 192.168.167.8
----
. Führen Sie die aus `nvme connect-all` Befehl über alle unterstützten NVMe/TCP Initiator-Ziel-LIFs der Nodes hinweg:
+
[listing]
----
nvme connect-all -t tcp -w host-traddr -a traddr
----
+
*Beispielausgabe:*

+
[listing]
----
#	nvme	connect-all	-t	tcp	-w	192.168.166.6	-a	192.168.166.7
#	nvme	connect-all	-t	tcp	-w	192.168.166.6	-a	192.168.166.8
#	nvme	connect-all	-t	tcp	-w	192.168.167.6	-a	192.168.167.7
#	nvme	connect-all	-t	tcp	-w	192.168.167.6	-a	192.168.167.8
----



NOTE: Ab RHEL 9.4 ist die Standardeinstellung für das NVMe/TCP `ctrl_loss_tmo`-Timeout deaktiviert. Dies bedeutet, dass die Anzahl der Wiederholungen (unbestimmter Versuch) nicht begrenzt ist. Daher müssen Sie bei Verwendung der Befehle oder `nvme connect-all` (Option -l ) keine bestimmte Zeitlimitdauer `nvme connect` manuell konfigurieren `ctrl_loss_tmo`. Bei diesem Standardverhalten treten für die NVMe/TCP-Controller bei einem Pfadausfall keine Timeouts auf und bleiben dauerhaft verbunden.



== NVMe-of validieren

Zur Validierung VON NVME-of gehen Sie wie folgt vor.

.Schritte
. Vergewissern Sie sich, dass das in-Kernel NVMe Multipath aktiviert ist:
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y
----
. Vergewissern Sie sich, dass die entsprechenden NVMe-of-Einstellungen (z. B. auf NetApp ONTAP-Controller gesetzt auf Modell und Load-Balancing-IOpolicy auf Round-Robin eingestellt) für die jeweiligen ONTAP-Namespaces den Host korrekt widerspiegeln:
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller
----
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. Überprüfen Sie, ob die Namespaces auf dem Host erstellt und richtig erkannt wurden:
+
[listing]
----
# nvme list
----
+
*Beispielausgabe:*

+
[listing]
----
Node         SN                   Model
---------------------------------------------------------
/dev/nvme4n1 81Ix2BVuekWcAAAAAAAB	NetApp ONTAP Controller


Namespace Usage    Format             FW             Rev
-----------------------------------------------------------
1                 21.47 GB / 21.47 GB	4 KiB + 0 B   FFFFFFFF
----
. Überprüfen Sie, ob der Controller-Status jedes Pfads aktiv ist und den korrekten ANA-Status aufweist:
+
[role="tabbed-block"]
====
.NVMe/FC
--
[listing]
----
# nvme list-subsys /dev/nvme5n21
----
*Beispielausgabe:*

[listing, subs="+quotes"]
----
nvme-subsys4 - NQN=nqn.1992-08.com.netapp:sn.efd7989cb10111ee871ed039ea954d18:subsystem.nvme
            hostnqn=nqn.2014-08.org.nvmexpress:uuid:d3b581b4-c975-11e6-8425-0894ef31a074
 iopolicy=round-robin
 \
  +- nvme2 fc traddr=nn-0x2013d039ea951c45:pn-0x2018d039ea951c45,host_traddr=nn-0x200000109bdacc76:pn-0x100000109bdacc76 live *non-optimized*
  +- nvme3 fc traddr=nn-0x2013d039ea951c45:pn-0x2017d039ea951c45,host_traddr=nn-0x200000109bdacc75:pn-0x100000109bdacc75 live *non-optimized*
  +- nvme5 fc traddr=nn-0x2013d039ea951c45:pn-0x2016d039ea951c45,host_traddr=nn-   0x200000109bdacc76:pn-0x100000109bdacc76 live *optimized*
  +- nvme6 fc traddr=nn-0x2013d039ea951c45:pn-0x2014d039ea951c45,host_traddr=nn-  0x200000109bdacc75:pn-0x100000109bdacc75 live *optimized*

----
--
.NVMe/TCP
--
[listing]
----
# nvme list-subsys /dev/nvme1n1
----
*Beispielausgabe:*

[listing, subs="+quotes"]
----

nvme-subsys1 -NQN=nqn.1992-08.com.netapp:
sn.983de7f4b39411ee871ed039ea954d18:subsystem.nvme_tcp_1         hostnqn=nqn.2014-08.org.nvmexpress:uuid:
4c4c4544-0035-5910-804b-c2c04f444d33
iopolicy=round-robin
\
+- nvme5 tcp traddr=192.168.166.7,trsvcid=4420,host_traddr=192.168.166.6,src_addr=192.168.166.6 *live*
+- nvme4 tcp traddr=192.168.166.8,trsvcid=4420,host_traddr=192.168.166.6,src_addr=192.168.166.6 *live*
+- nvme2 tcp traddr=192.168.167.7,trsvcid=4420,host_traddr=192.168.167.6,src_addr=192.168.167.6 *live*
+- nvme1 tcp traddr=192.168.167.8,trsvcid=4420,host_traddr=192.168.167.6,src_addr=192.168.167.6 *live*

----
--
====
. Vergewissern Sie sich, dass das NetApp Plug-in für jedes ONTAP Namespace-Gerät die richtigen Werte anzeigt:
+
[role="tabbed-block"]
====
.Spalte
--
[listing]
----
# nvme netapp ontapdevices -o column
----
*Beispielausgabe:*

[listing]
----
Device        Vserver   Namespace Path
----------------------- ------------------------------
/dev/nvme0n1 vs_tcp           /vol/vol1/ns1



NSID       UUID                                   Size
------------------------------------------------------------
1          6fcb8ea0-dc1e-4933-b798-8a62a626cb7f	21.47GB
----
--
.JSON
--
[listing]
----
# nvme netapp ontapdevices -o json
----
*Beispielausgabe*

[listing]
----
{

"ONTAPdevices" : [
{

"Device" : "/dev/nvme1n1", "Vserver" : "linux_tcnvme_iscsi", "Namespace_Path" : "/vol/tcpnvme_1_0_0/tcpnvme_ns", "NSID" : 1,
"UUID" : "1a42c652-1450-4a29-886a-b4ccc23e637d", "Size" : "21.47GB",
"LBA_Data_Size" : 4096,
"Namespace_Size" : 5242880
},

]
}


----
--
====




== Bekannte Probleme

Es sind keine Probleme bei der NVMe-of Hostkonfiguration für RHEL 9.4 mit ONTAP-Release bekannt.
