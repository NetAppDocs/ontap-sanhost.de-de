---
sidebar: sidebar 
permalink: nvme_rhel_90.html 
keywords: nvme, linux, rhel, red hat, enterprise 
summary: Konfigurieren von NVMe-of Host für RHEL 9.0 mit ONTAP 
---
= NVMe-of Hostkonfiguration für RHEL 9.0 mit ONTAP
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
NVMe-of (einschließlich NVMe/FC und NVMe/TCP) wird mit RHEL 9.0 mit Asymmetric Namespace Access (ANA) unterstützt, die für die verbleibenden Storage-Failover (SFOs) auf dem ONTAP Array erforderlich sind. ANA ist das ALUA-Äquivalent in der NVM-of-Umgebung und ist derzeit mit NVMe Multipath im Kernel implementiert. Mit diesem Verfahren können Sie NVMe-of mit in-Kernel NVMe Multipath unter Verwendung von ANA auf RHEL 9.0 und ONTAP als Ziel aktivieren.

Weitere Informationen zu unterstützten Konfigurationen finden Sie im link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitäts-Matrix-Tool"^].



== Funktionen

* Ab RHEL 9.0 ist NVMe/TCP keine Technologie-Vorschaufunktion mehr (im Gegensatz zu RHEL 8), sondern eine vollständig unterstützte Unternehmensfunktion selbst.
* Ab RHEL 9.0 ist NVMe Multipath im Kernel standardmäßig für NVMe-Namespaces aktiviert, ohne dass explizite Einstellungen erforderlich sind (im Gegensatz zu RHEL 8).




== Bekannte Einschränkungen

Das Booten von SAN über das NVMe-of-Protokoll wird derzeit nicht unterstützt.



== Aktivieren Sie NVMe Multipath im Kernel

Sie können das folgende Verfahren verwenden, um in-Kernel NVMe Multipath zu aktivieren.

.Schritte
. Installieren Sie RHEL 9.0 auf dem Server.
. Stellen Sie nach Abschluss der Installation sicher, dass Sie den angegebenen RHEL 9.0-Kernel ausführen. Siehe link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitätsmatrix"^] Erhalten Sie auf der aktuellen Liste der unterstützten Versionen.
+
[listing]
----
# uname -r
5.14.0-70.13.1.el9_0.x86_64
----
. Installieren Sie den `nvme-cli` Paket.
+
[listing]
----
# rpm -qa|grep nvme-cli
nvme-cli-1.16-3.el9.x86_64
----
. Überprüfen Sie auf dem Host die NQN-Zeichenfolge des Hosts bei `/etc/nvme/hostnqn` Und überprüfen Sie, ob es mit der NQN-Zeichenfolge des Hosts für das entsprechende Subsystem auf dem ONTAP-Array übereinstimmt. Beispiel:
+
[listing]
----
# cat /etc/nvme/hostnqn
nqn.2014-08.org.nvmexpress:uuid:9ed5b327-b9fc-4cf5-97b3-1b5d986345d1
----
+
[listing]
----
::> vserver nvme subsystem host show -vserver vs_fcnvme_141
Vserver     Subsystem Host     NQN
----------- --------------- ----------------------------------------------------------
vs_fcnvme_14 nvme_141_1 nqn.2014-08.org.nvmexpress:uuid:9ed5b327-b9fc-4cf5-97b3-1b5d986345d1
----
+

NOTE: Wenn die Host-NQN-Strings nicht übereinstimmen, sollten Sie den verwenden `vserver modify` Befehl zum Aktualisieren der NQN-Zeichenfolge des Hosts auf dem entsprechenden ONTAP-NVMe-Subsystem, um die NQN-Zeichenfolge des Hosts von zu entsprechen `/etc/nvme/hostnqn` Auf dem Host.

. Starten Sie den Host neu.




== Konfiguration von NVMe/FC

Sie können NVMe/FC für Broadcom/Emulex- oder Marvell/Qlogic-Adapter konfigurieren.

[role="tabbed-block"]
====
.Broadcom/Emulex
--
.Schritte
. Vergewissern Sie sich, dass Sie den unterstützten Adapter verwenden. Weitere Informationen zu unterstützten Adaptern finden Sie im link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitäts-Matrix-Tool"^].
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
LPe32002-M2
LPe32002-M2
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/modeldesc
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
----
. Überprüfen Sie, ob Sie die empfohlene Broadcom lpfc-Firmware und den Posteingangstreiber verwenden. Die aktuelle Liste der unterstützten Adaptertreiber- und Firmware-Versionen finden Sie unter link:https://mysupport.netapp.com/matrix/["NetApp Interoperabilitätsmatrix"^].
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
12.8.351.47, sli-4:2:c
12.8.351.47, sli-4:2:c
----
+
[listing]
----
# cat /sys/module/lpfc/version
0:14.0.0.4
----
. Verifizieren Sie das `lpfc_enable_fc4_type` Ist auf festgelegt `3`.
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. Überprüfen Sie, ob die Initiator-Ports aktiv sind und ausgeführt werden, und Sie können die Ziel-LIFs sehen.
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x100000109b1c1204
0x100000109b1c1205
----
+
[listing]
----
# cat /sys/class/fc_host/host*/port_state
Online
Online
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/nvme_info

NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109b1c1204 WWNN x200000109b1c1204 DID x011d00 ONLINE
NVME RPORT WWPN x203800a098dfdd91 WWNN x203700a098dfdd91 DID x010c07 TARGET DISCSRVC ONLINE
NVME RPORT WWPN x203900a098dfdd91 WWNN x203700a098dfdd91 DID x011507 TARGET DISCSRVC ONLINE

NVME Statistics
LS: Xmt 0000000f78 Cmpl 0000000f78 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000002fe29bba Issue 000000002fe29bc4 OutIO 000000000000000a
abort 00001bc7 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00001e15 Err 0000d906

NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109b1c1205 WWNN x200000109b1c1205 DID x011900 ONLINE
NVME RPORT WWPN x203d00a098dfdd91 WWNN x203700a098dfdd91 DID x010007 TARGET DISCSRVC ONLINE
NVME RPORT WWPN x203a00a098dfdd91 WWNN x203700a098dfdd91 DID x012a07 TARGET DISCSRVC ONLINE

NVME Statistics
LS: Xmt 0000000fa8 Cmpl 0000000fa8 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000002e14f170 Issue 000000002e14f17a OutIO 000000000000000a
abort 000016bb noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00001f50 Err 0000d9f8
----


--
.Marvell/QLogic
--
Der native Inbox qla2xxx Treiber, der im RHEL 9.0 Kernel enthalten ist, hat die neuesten Fehlerbehebungen. Diese Fehlerbehebungen sind für die Unterstützung von ONTAP unerlässlich.

.Schritte
. Vergewissern Sie sich, dass der unterstützte Adaptertreiber und die unterstützten Firmware-Versionen ausgeführt werden:


[listing]
----
# cat /sys/class/fc_host/host*/symbolic_name
QLE2742 FW:v9.06.02 DVR:v10.02.00.200-k
QLE2742 FW:v9.06.02 DVR:v10.02.00.200-k
----
. Verifizieren `ql2xnvmeenable` Ist gesetzt, sodass der Marvell-Adapter als NVMe/FC-Initiator fungieren kann:


[listing]
----
# cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
1
----
--
====


=== 1 MB E/A aktivieren (optional)

ONTAP meldet eine MDTS (MAX Data-Übertragungsgröße) von 8 in den Identifizieren von Controller-Daten. Das bedeutet, dass die maximale E/A-Anforderungsgröße bis zu 1 MB betragen kann. Um I/O-Anforderungen von Größe 1 MB für einen Broadcom-NVMe/FC-Host auszustellen, müssen Sie den `lpfc` Wert des `lpfc_sg_seg_cnt` Parameters ab dem Standardwert 64 auf 256 erhöhen.


NOTE: Die folgenden Schritte gelten nicht für Qlogic NVMe/FC-Hosts.

.Schritte
. Setzen Sie den `lpfc_sg_seg_cnt` Parameter auf 256:
+
[listing]
----
cat /etc/modprobe.d/lpfc.conf
----
+
[listing]
----
options lpfc lpfc_sg_seg_cnt=256
----
. Führen Sie den Befehl aus `dracut -f`, und starten Sie den Host neu:
. Stellen Sie sicher, dass `lpfc_sg_seg_cnt` 256:
+
[listing]
----
cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
----
+
Der erwartete Wert ist 256.





== Konfiguration von NVMe/TCP

NVMe/TCP verfügt nicht über eine automatische Verbindungsfunktion. Wenn also ein Pfad ausfällt und nicht innerhalb der standardmäßigen Time-Out-Frist von 10 Minuten wieder hergestellt wird, kann NVMe/TCP die Verbindung nicht automatisch wiederherstellen. Um ein Timeout zu verhindern, sollten Sie den Wiederholungszeitraum für Failover-Ereignisse auf mindestens 30 Minuten einstellen.

.Schritte
. Überprüfen Sie, ob der Initiator-Port die Daten der Erkennungsprotokollseiten in den unterstützten NVMe/TCP LIFs abrufen kann:
+
[listing]
----
# nvme discover -t tcp -w 192.168.1.8 -a 192.168.1.51

Discovery Log Number of Records 10, Generation counter 119
=====Discovery Log Entry 0======
trtype: tcp
adrfam: ipv4
subtype: nvme subsystem
treq: not specified
portid: 0
trsvcid: 4420
subnqn: nqn.1992-08.com.netapp:sn.56e362e9bb4f11ebbaded039ea165abc:subsystem.nvme_118_tcp_1
traddr: 192.168.2.56
sectype: none
=====Discovery Log Entry 1======
trtype: tcp
adrfam: ipv4
subtype: nvme subsystem
treq: not specified
portid: 1
trsvcid: 4420
subnqn: nqn.1992-08.com.netapp:sn.56e362e9bb4f11ebbaded039ea165abc:subsystem.nvme_118_tcp_1
traddr: 192.168.1.51
sectype: none
=====Discovery Log Entry 2======
trtype: tcp
adrfam: ipv4
subtype: nvme subsystem
treq: not specified
portid: 0
trsvcid: 4420
subnqn: nqn.1992-08.com.netapp:sn.56e362e9bb4f11ebbaded039ea165abc:subsystem.nvme_118_tcp_2
traddr: 192.168.2.56
sectype: none
...
----
. Ebenso überprüfen Sie, dass die anderen NVMe/TCP Initiator-Ziel-LIF-Combos in der Lage sind, die Discovery-Protokoll-Seitendaten erfolgreich abzurufen. Beispiel:
+
[listing]
----
# nvme discover -t tcp -w 192.168.1.8 -a 192.168.1.51
# nvme discover -t tcp -w 192.168.1.8 -a 192.168.1.52
# nvme discover -t tcp -w 192.168.2.9 -a 192.168.2.56
# nvme discover -t tcp -w 192.168.2.9 -a 192.168.2.57
----
. Laufen `nvme connect-all` Befehl über alle unterstützten NVMe/TCP-Initiator-Ziel-LIFs über die Nodes hinweg Stellen Sie einen längeren Zeitraum ein `ctrl_loss_tmo` Zeitschaltuhr-Wiederholungszeitraum (z. B. 30 Minuten, die über eingestellt werden kann `-l 1800`) Während des connect-all, so dass es für einen längeren Zeitraum im Falle eines Pfadverlusts erneut versuchen würde. Beispiel:
+
[listing]
----
# nvme connect-all -t tcp -w 192.168.1.8 -a 192.168.1.51 -l 1800
# nvme connect-all -t tcp -w 192.168.1.8 -a 192.168.1.52 -l 1800
# nvme connect-all -t tcp -w 192.168.2.9 -a 192.168.2.56 -l 1800
# nvme connect-all -t tcp -w 192.168.2.9 -a 192.168.2.57 -l 1800
----




== NVMe-of validieren

Zur Validierung von NVMe-of gehen Sie wie folgt vor.

.Schritte
. Überprüfung des NVMe Multipath im Kernel durch Prüfung:
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y
----
. Stellen Sie sicher, dass die entsprechenden NVMf-Einstellungen (z. B. Modell auf gesetzt) verwendet werden `NetApp ONTAP Controller` Und Lastverteilung `iopolicy` Auf einstellen `round-robin`) Für die jeweiligen ONTAP-Namespaces richtig reflektieren auf dem Host:
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller
----
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. Vergewissern Sie sich, dass die ONTAP-Namespaces auf dem Host ordnungsgemäß reflektieren.
+
Beispiel (A):

+
[listing]
----
# nvme list
Node         SN                    Model                   Namespace   Usage
------      ---------------------------------------      ------------------------
/dev/nvme0n1 814vWBNRwf9HAAAAAAAB  NetApp ONTAP Controller  1          85.90 GB / 85.90 GB

Format         FW Rev
---------------------
4 KiB + 0 B   FFFFFFFF
----
+
Beispiel (b):

+
[listing]
----
# nvme list
Node           SN                   Model                    Namespace   Usage
---------------------------------------------------- ------------------------------------
/dev/nvme0n1   81CZ5BQuUNfGAAAAAAAB NetApp ONTAP Controller   1         85.90 GB / 85.90 GB

Format         FW Rev
-----------------------
4 KiB + 0 B   FFFFFFFF
----
. Überprüfen Sie, ob der Controller-Status jedes Pfads aktiv ist und den korrekten ANA-Status aufweist.
+
Beispiel (A):

+
[listing]
----
# nvme list-subsys /dev/nvme0n1
nvme-subsys0 - NQN=nqn.1992-08.com.netapp:sn.5f5f2c4aa73b11e9967e00a098df41bd:subsystem.nvme_141_1
\
+- nvme0 fc traddr=nn-0x203700a098dfdd91:pn-0x203800a098dfdd91 host_traddr=nn-0x200000109b1c1204:pn-0x100000109b1c1204 live inaccessible
+- nvme1 fc traddr=nn-0x203700a098dfdd91:pn-0x203900a098dfdd91 host_traddr=nn-0x200000109b1c1204:pn-0x100000109b1c1204 live inaccessible
+- nvme2 fc traddr=nn-0x203700a098dfdd91:pn-0x203a00a098dfdd91 host_traddr=nn-0x200000109b1c1205:pn-0x100000109b1c1205 live optimized
+- nvme3 fc traddr=nn-0x203700a098dfdd91:pn-0x203d00a098dfdd91 host_traddr=nn-0x200000109b1c1205:pn-0x100000109b1c1205 live optimized
----
+
Beispiel (b):

+
[listing]
----
# nvme list-subsys /dev/nvme0n1
nvme-subsys0 - NQN=nqn.1992-08.com.netapp:sn.56e362e9bb4f11ebbaded039ea165abc:subsystem.nvme_118_tcp_1
\
+- nvme0 tcp traddr=192.168.1.51 trsvcid=4420 host_traddr=192.168.1.8 live optimized
+- nvme10 tcp traddr=192.168.2.56 trsvcid=4420 host_traddr=192.168.2.9 live optimized
+- nvme15 tcp traddr=192.168.2.57 trsvcid=4420 host_traddr=192.168.2.9 live non-optimized
+- nvme5 tcp traddr=192.168.1.52 trsvcid=4420 host_traddr=192.168.1.8 live non-optimized
----
. Überprüfen Sie, ob das NetApp Plug-in die richtigen Werte für die einzelnen ONTAP Namespace-Geräte anzeigt.
+
Beispiel (A):

+
[listing]
----
# nvme netapp ontapdevices -o column
Device       Vserver        Namespace Path                            NSID
----------------------- ------------------------------ -------------------------
/dev/nvme0n1  vs_fcnvme_141  /vol/fcnvme_141_vol_1_1_0/fcnvme_141_ns   1

UUID                                   Size
--------------------------------------------
72b887b1-5fb6-47b8-be0b-33326e2542e2   85.90GB
----
+
[listing]
----
# nvme netapp ontapdevices -o json
{
"ONTAPdevices" : [
    {
        "Device" : "/dev/nvme0n1",
        "Vserver" : "vs_fcnvme_141",
        "Namespace_Path" : "/vol/fcnvme_141_vol_1_1_0/fcnvme_141_ns",
        "NSID" : 1,
        "UUID" : "72b887b1-5fb6-47b8-be0b-33326e2542e2",
        "Size" : "85.90GB",
        "LBA_Data_Size" : 4096,
        "Namespace_Size" : 20971520
    }
  ]
}
----
+
Beispiel (b):

+
[listing]
----
# nvme netapp ontapdevices -o column
Device               Vserver                   Namespace Path
--------------------- ------------------------- ------------------------------------
/dev/nvme0n1         vs_tcp_118                /vol/tcpnvme_118_1_0_0/tcpnvme_118_ns

NSID   UUID                               Size
-------------------------------------------------
1     4a3e89de-b239-45d8-be0c-b81f6418283c 85.90GB
----
+
[listing]
----
# nvme netapp ontapdevices -o json
{
"ONTAPdevices" : [
    {
     "Device" : "/dev/nvme0n1",
      "Vserver" : "vs_tcp_118",
      "Namespace_Path" : "/vol/tcpnvme_118_1_0_0/tcpnvme_118_ns",
      "NSID" : 1,
      "UUID" : "4a3e89de-b239-45d8-be0c-b81f6418283c",
      "Size" : "85.90GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 20971520
    },
  ]

}
----




== Bekannte Probleme

Die NVMe-of-Hostkonfiguration für RHEL 9.0 mit ONTAP weist folgende bekannte Probleme auf:

[cols="20,40,40"]
|===
| NetApp Bug ID | Titel | Beschreibung 


| link:https://mysupport.netapp.com/site/bugs-online/product/HOSTUTILITIES/BURT/1479047["1479047"^] | RHEL 9.0 NVMe-of-Hosts erstellen duplizierte persistente Discovery-Controller | Auf NVMe over Fabrics-Hosts (NVMe-of) können Sie den Befehl „nvme discover -p“ verwenden, um persistente Discovery Controller (PDCs) zu erstellen. Wenn dieser Befehl verwendet wird, sollte pro Initiator-Zielkombination nur ein PDC erstellt werden. Wenn Sie jedoch ONTAP 9.10.1 und Red hat Enterprise Linux (RHEL) 9.0 mit einem NVMe-of-Host ausführen, wird bei jeder Ausführung von NVMe discover -p ein doppelter PDC erstellt. Dies führt zu einer unnötigen Nutzung der Ressourcen auf dem Host und dem Ziel. 
|===